{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN:\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_actions,\n",
    "            n_features,\n",
    "            learning_rate=0.001,\n",
    "            reward_decay=0.9,\n",
    "            e_greedy=0.9,\n",
    "            replace_target_iter=200,\n",
    "            memory_size=500,\n",
    "            batch_size=32,\n",
    "            e_greedy_increment=None,\n",
    "            output_graph=False,\n",
    "            dueling=True,\n",
    "            sess=None,\n",
    "            number=3\n",
    "    ):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_features = n_features\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon_max = e_greedy\n",
    "        self.replace_target_iter = replace_target_iter\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon_increment = e_greedy_increment\n",
    "        self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max\n",
    "\n",
    "        self.dueling = dueling      # decide to use dueling DQN or not\n",
    "\n",
    "        self.learn_step_counter = 0\n",
    "        self.BS_number=number\n",
    "        self.memory = np.zeros((self.memory_size, (n_features-2)*number*2+2))\n",
    "        self._build_net()\n",
    "        if sess is None:\n",
    "            self.sess = tf.Session()\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "        else:\n",
    "            self.sess = sess\n",
    "        if output_graph:\n",
    "            tf.summary.FileWriter(\"logs/\", self.sess.graph)\n",
    "#         self.cost_his = []\n",
    "\n",
    "    def _build_net(self):\n",
    "        def build_layers(s, c_names, n_l1, w_initializer, b_initializer):\n",
    "            with tf.variable_scope('l1'):\n",
    "                w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w_initializer, collections=c_names)\n",
    "                b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names)\n",
    "                l1 = tf.nn.relu(tf.matmul(s, w1) + b1)\n",
    "\n",
    "            if self.dueling:\n",
    "                # Dueling DQN\n",
    "                with tf.variable_scope('Value'):\n",
    "                    w2 = tf.get_variable('w2', [n_l1, 1], initializer=w_initializer, collections=c_names)\n",
    "                    b2 = tf.get_variable('b2', [1, 1], initializer=b_initializer, collections=c_names)\n",
    "                    self.V = tf.matmul(l1, w2) + b2\n",
    "\n",
    "                with tf.variable_scope('Advantage'):\n",
    "                    w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)\n",
    "                    b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names)\n",
    "                    self.A = tf.matmul(l1, w2) + b2\n",
    "\n",
    "                with tf.variable_scope('Q'):\n",
    "                    out = self.V + (self.A - tf.reduce_mean(self.A, axis=1, keep_dims=True))     # Q = V(s) + A(s,a)\n",
    "            else:\n",
    "                with tf.variable_scope('Q'):\n",
    "                    w2 = tf.get_variable('w2', [n_l1, self.n_actions], initializer=w_initializer, collections=c_names)\n",
    "                    b2 = tf.get_variable('b2', [1, self.n_actions], initializer=b_initializer, collections=c_names)\n",
    "                    out = tf.matmul(l1, w2) + b2\n",
    "            print('build %s'%c_names)\n",
    "            return out\n",
    "\n",
    "        # ------------------ build evaluate_net ------------------\n",
    "        self.s=[]\n",
    "        self.q_target=[]\n",
    "        self.q_eval=[]\n",
    "        self.loss=[]\n",
    "        self._train_op=[]\n",
    "        self.s_=[]\n",
    "        self.q_next=[]\n",
    "        \n",
    "        for i in range(self.BS_number):\n",
    "            self.s.append(tf.placeholder(tf.float32, [None, self.n_features], name='s'+str(i)))\n",
    "            self.q_target.append(tf.placeholder(tf.float32, [None, self.n_actions], name='Q_target'+str(i)))\n",
    "#         self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s')  # input\n",
    "#         self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name='Q_target')  # for calculating loss\n",
    "        for i in range(self.BS_number):\n",
    "            print(i)\n",
    "            with tf.variable_scope('eval_net'+str(i)):\n",
    "                c_names, n_l1, w_initializer, b_initializer = \\\n",
    "                    ['eval_net_params'+str(i), tf.GraphKeys.GLOBAL_VARIABLES], 20, \\\n",
    "                    tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)  # config of layers\n",
    "\n",
    "                self.q_eval.append(build_layers(self.s[i], c_names, n_l1, w_initializer, b_initializer))\n",
    "\n",
    "            with tf.variable_scope('loss'+str(i)):\n",
    "                self.loss.append(tf.reduce_mean(tf.squared_difference(self.q_target[i], self.q_eval[i])))\n",
    "        for i in range(self.BS_number):\n",
    "            with tf.variable_scope('train'+str(i)):\n",
    "                self._train_op.append(tf.train.RMSPropOptimizer(self.lr).minimize(self.loss[i]))\n",
    "        print('build evaluate net succeed')\n",
    "\n",
    "        # ------------------ build target_net ------------------\n",
    "        for i in range(self.BS_number):\n",
    "            self.s_.append(tf.placeholder(tf.float32, [None, self.n_features], name='s_'+str(i))) \n",
    "            # input\n",
    "        for i in range(self.BS_number):\n",
    "            with tf.variable_scope('target_net'+str(i)):\n",
    "                c_names = ['target_net_params'+str(i), tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "                print(w_initializer)\n",
    "\n",
    "                self.q_next.append(build_layers(self.s_[i], c_names, n_l1, w_initializer, b_initializer))\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "#####以上是在建立N个神经网络\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        if not hasattr(self, 'memory_counter'):\n",
    "            self.memory_counter = 0\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        action=[0,0,0]\n",
    "        for i in range(self.BS_number):\n",
    "            index=list(np.arange(i*(self.n_features-2),(i+1)*(self.n_features-2)))\n",
    "            index.append(self.BS_number*(feature-2))\n",
    "            index.append(self.BS_number*(feature-2)+1)\n",
    "            observation_temp=observation[index]\n",
    "            observation_temp=observation_temp[np.newaxis,:]\n",
    "            if np.random.uniform() < self.epsilon:  # choosing action\n",
    "                actions_value = self.sess.run(self.q_eval[i], feed_dict={self.s[i]: observation_temp})\n",
    "                action[i] = np.argmax(actions_value)\n",
    "            else:\n",
    "                action[i] = np.random.randint(0, self.n_actions)\n",
    "        action_count=''\n",
    "        for i in range(self.BS_number):\n",
    "            action_count+=str(int(action[i]))\n",
    "        # print (action_count)\n",
    "        action_count=int(action_count,2)\n",
    "        return action\n",
    "\n",
    "    def _replace_target_params(self):\n",
    "        for i in range(self.BS_number):\n",
    "            \n",
    "            t_params = tf.get_collection('target_net_params'+str(i))\n",
    "            e_params = tf.get_collection('eval_net_params'+str(i))\n",
    "            self.sess.run([tf.assign(t, e) for t, e in zip(t_params, e_params)])\n",
    "\n",
    "    def learn(self):\n",
    "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
    "            self._replace_target_params()\n",
    "            print('\\ntarget_params_replaced\\n')\n",
    "\n",
    "        for i in range(self.BS_number):\n",
    "            \n",
    "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
    "            batch_memory = self.memory[sample_index, :]\n",
    "            index_=list(np.arange((self.BS_number+i)*(self.n_features-2)+4,(self.BS_number+i+1)*(self.n_features-2)+4))\n",
    "            index_.append(-2)\n",
    "            index_.append(-1)\n",
    "# feature=6\n",
    "# y = np.arange((((feature-2)*3+2)*2+2)*10).reshape(10,(((feature-2)*3+2)*2+2))\n",
    "# for i in range(3):\n",
    "#     print('bs',i)\n",
    "#     index=list(np.arange((3+i)*(feature-2)+4,(3+i)*(feature-2)+4+4))\n",
    "#     index.append(-2)\n",
    "#     index.append(-1)\n",
    "#     print(y[:,index])\n",
    "            observation_=batch_memory[:,index_]\n",
    "            q_next, q_eval4next,  = self.sess.run(\n",
    "                [self.q_next[i], self.q_eval[i]],\n",
    "                feed_dict={self.s_: observation_,    # next observation\n",
    "                           self.s: observation_})    # next observation\n",
    "            index=list(np.arange(i*(self.n_features-2),(i+1)*(self.n_features-2)))\n",
    "            index.append(self.BS_number*(feature-2))\n",
    "            index.append(self.BS_number*(feature-2)+1)\n",
    "#     index=list(np.arange(i*(feature-2),(i+1)*(feature-2)))\n",
    "#     index.append(3*(feature-2))\n",
    "#     index.append(3*(feature-2)+1)\n",
    "            q_eval = self.sess.run(self.q_eval[i], {self.s[i]: batch_memory[:, index]})\n",
    "\n",
    "            q_target = q_eval.copy()\n",
    "\n",
    "            batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "            eval_act_index = batch_memory[:, (self.n_features-2)*self.BS_number*2].astype(int)\n",
    "            reward = batch_memory[:, (self.n_features-2)*self.BS_number*2 + 1]\n",
    "\n",
    "            q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis=1)\n",
    "\n",
    "            _, self.cost = self.sess.run([self._train_op[i], self.loss[i]],\n",
    "                                     feed_dict={self.s[i]: batch_memory[:, index],\n",
    "                                                self.q_target[i]: q_target})\n",
    "#         self.cost_his.append(self.cost)\n",
    "\n",
    "        self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon < self.epsilon_max else self.epsilon_max\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "build ['eval_net_params0', 'variables']\n",
      "1\n",
      "build ['eval_net_params1', 'variables']\n",
      "2\n",
      "build ['eval_net_params2', 'variables']\n",
      "build evaluate net succeed\n",
      "<tensorflow.python.ops.init_ops.RandomNormal object at 0x7f7d461c1fd0>\n",
      "build ['target_net_params0', 'variables']\n",
      "<tensorflow.python.ops.init_ops.RandomNormal object at 0x7f7d461c1fd0>\n",
      "build ['target_net_params1', 'variables']\n",
      "<tensorflow.python.ops.init_ops.RandomNormal object at 0x7f7d461c1fd0>\n",
      "build ['target_net_params2', 'variables']\n"
     ]
    }
   ],
   "source": [
    "a=DuelingDQN(n_actions=2,n_features=10,output_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition = np.hstack((s, a, r, s_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=[1,2,3,4]\n",
    "a=6\n",
    "r=12\n",
    "s_=[2,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  6, 12,  2,  4,  5,  6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29],\n",
       "       [ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59],\n",
       "       [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
       "         73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
       "         86,  87,  88,  89],\n",
       "       [ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "        103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "        116, 117, 118, 119],\n",
       "       [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
       "        133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "        146, 147, 148, 149],\n",
       "       [150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
       "        163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
       "        176, 177, 178, 179],\n",
       "       [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "        193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "        206, 207, 208, 209],\n",
       "       [210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "        236, 237, 238, 239],\n",
       "       [240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
       "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "        266, 267, 268, 269],\n",
       "       [270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
       "        283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
       "        296, 297, 298, 299]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,2,3,4,5,6],[4,5,6,7,10,11],[1,4,5,7,14,12],[4,5,7,8,44,89]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs 0\n",
      "[[  0   1   2   3  12  13]\n",
      " [ 30  31  32  33  42  43]\n",
      " [ 60  61  62  63  72  73]\n",
      " [ 90  91  92  93 102 103]\n",
      " [120 121 122 123 132 133]\n",
      " [150 151 152 153 162 163]\n",
      " [180 181 182 183 192 193]\n",
      " [210 211 212 213 222 223]\n",
      " [240 241 242 243 252 253]\n",
      " [270 271 272 273 282 283]]\n",
      "bs 1\n",
      "[[  4   5   6   7  12  13]\n",
      " [ 34  35  36  37  42  43]\n",
      " [ 64  65  66  67  72  73]\n",
      " [ 94  95  96  97 102 103]\n",
      " [124 125 126 127 132 133]\n",
      " [154 155 156 157 162 163]\n",
      " [184 185 186 187 192 193]\n",
      " [214 215 216 217 222 223]\n",
      " [244 245 246 247 252 253]\n",
      " [274 275 276 277 282 283]]\n",
      "bs 2\n",
      "[[  8   9  10  11  12  13]\n",
      " [ 38  39  40  41  42  43]\n",
      " [ 68  69  70  71  72  73]\n",
      " [ 98  99 100 101 102 103]\n",
      " [128 129 130 131 132 133]\n",
      " [158 159 160 161 162 163]\n",
      " [188 189 190 191 192 193]\n",
      " [218 219 220 221 222 223]\n",
      " [248 249 250 251 252 253]\n",
      " [278 279 280 281 282 283]]\n"
     ]
    }
   ],
   "source": [
    "feature=6\n",
    "y = np.arange((((feature-2)*3+2)*2+2)*10).reshape(10,(((feature-2)*3+2)*2+2))\n",
    "for i in range(3):\n",
    "    print('bs',i)\n",
    "    index=list(np.arange(i*(feature-2),(i+1)*(feature-2)))\n",
    "    index.append(3*(feature-2))\n",
    "    index.append(3*(feature-2)+1)\n",
    "    print(y[:,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2,3,4])\n",
    "a[[0,1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
